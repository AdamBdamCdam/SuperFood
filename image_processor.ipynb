{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "\n",
    "This python program was created to, process the images, which will be used to train our CNN. \n",
    "\n",
    "The program loads the images from the 'Puctures' directory, then rotates them 90 degrees clockwize, to make them appear up right.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Made with help from:\n",
    "1. https://www.geeksforgeeks.org/image-processing-in-python/\n",
    "2. ChatGPT\n",
    "'''\n",
    "\n",
    "dir = '../Local_Things/Pictures/'  # Ensure correct path\n",
    "\n",
    "plot = False\n",
    "\n",
    "# Image list sorted by modification timestamp\n",
    "image_list = sorted(\n",
    "    [img for img in os.listdir(dir) if img.endswith('.jpg')]\n",
    ")\n",
    "\n",
    "# Image rotation parameters\n",
    "angle = -90\n",
    "scale = 1\n",
    "\n",
    "# List of processed images\n",
    "p_images = []\n",
    "\n",
    "for img_name in image_list:\n",
    "    img_path = os.path.join(dir, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Skipping {img_name}, could not read.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Convert BGR to RGB\n",
    "        image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # resize image to 150 px by 150 px\n",
    "        resized_image = cv2.resize(src = image_rgb, \n",
    "                          dsize=(150, 150), \n",
    "                          interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Define rotation parameters\n",
    "        center = (resized_image.shape[1] // 2, resized_image.shape[0] // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "        \n",
    "        # Rotate image\n",
    "        rotated_image = cv2.warpAffine(resized_image, rotation_matrix, (resized_image.shape[1], resized_image.shape[0]))\n",
    "\n",
    "        # add rotated_image to p_images\n",
    "        p_images.append(rotated_image)\n",
    "\n",
    "        # Plot rotated image \n",
    "        if plot:\n",
    "            plt.figure(figsize=(5, 5))  # Create new figure\n",
    "            plt.imshow(rotated_image)\n",
    "            plt.title(f'Rotated Image: {img_name}')\n",
    "            plt.xticks([])  # Remove x-axis ticks\n",
    "            plt.yticks([])  # Remove y-axis ticks\n",
    "            plt.show()\n",
    "\n",
    "        # Free memory\n",
    "        del img, image_rgb, rotated_image, resized_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Training\n",
    "\n",
    "We're using a sequencial model from the getting started section of the tensorflow website:\n",
    "https://www.tensorflow.org/tutorials/quickstart/beginner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 3)\n",
      "x_train shape: (132, 150, 150, 3)\n",
      "y_train shape: (132, 3)\n",
      "Epoch 1/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 184ms/step - accuracy: 0.3703 - loss: 3.0792\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.3288 - loss: 1.2722\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 0.3757 - loss: 1.0913\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.4134 - loss: 1.0928\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 0.3862 - loss: 1.0910\n",
      "2/2 - 0s - 173ms/step - accuracy: 0.2121 - loss: 1.1256\n",
      "tf.Tensor(\n",
      "[[0.29544908 0.41090515 0.2936458 ]\n",
      " [0.28559667 0.42834324 0.28606012]\n",
      " [0.312504   0.38429156 0.30320442]\n",
      " [0.31165096 0.38531545 0.3030336 ]\n",
      " [0.28959304 0.42492247 0.28548443]], shape=(5, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# convert p_images to numpy.array:\n",
    "\n",
    "# Convert processed images to a NumPy array\n",
    "X = np.array(p_images, dtype=np.float32) / 255.0  # Normalize\n",
    "\n",
    "# Dummy labels (replace with actual labels if available)\n",
    "num_classes = 3  # Adjust based on your dataset\n",
    "y = np.random.randint(0, num_classes, size=(len(p_images),))\n",
    "\n",
    "# One-hot encode labels\n",
    "y = tf.keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "# Split into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now X_train, y_train, X_test, y_test are ready for TensorFlow\n",
    "\n",
    "\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Define a CNN model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(3)  # No softmax here, since we'll use `from_logits=True`\n",
    "])\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "# Compile the model with correct loss function\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Ensure x_train and y_train are in the correct format\n",
    "print(f\"x_train shape: {x_train.shape}\")  # Should be (num_samples, 150, 150, 3)\n",
    "print(f\"y_train shape: {y_train.shape}\")  # Should be (num_samples,)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# Evaluate on test set\n",
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# Create a probability model for predictions\n",
    "probability_model = tf.keras.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "# Get predictions\n",
    "predictions = probability_model(x_test[:5])\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
